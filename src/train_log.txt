All model checkpoint layers were used when initializing TFGPT2LMHeadModel.

All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at ../model/gpt_ckpt.
If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.
2022-01-14 07:42:28.175984: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10
7788/7788 [==============================] - 2770s 354ms/step - loss: 2.4723 - accuracy_function: 0.2561 - val_loss: 2.3873 - val_accuracy_function: 0.2746
Epoch 2/10
7788/7788 [==============================] - 2772s 356ms/step - loss: 2.1723 - accuracy_function: 0.2851 - val_loss: 2.3022 - val_accuracy_function: 0.2922
Epoch 3/10
7788/7788 [==============================] - 2771s 356ms/step - loss: 2.0219 - accuracy_function: 0.2990 - val_loss: 2.2651 - val_accuracy_function: 0.3041
Epoch 4/10
7788/7788 [==============================] - 2771s 356ms/step - loss: 1.9040 - accuracy_function: 0.3097 - val_loss: 2.2424 - val_accuracy_function: 0.3139
Epoch 5/10
7788/7788 [==============================] - 2773s 356ms/step - loss: 1.7993 - accuracy_function: 0.3188 - val_loss: 2.2442 - val_accuracy_function: 0.3227
Epoch 6/10
7788/7788 [==============================] - 2772s 356ms/step - loss: 1.7041 - accuracy_function: 0.3272 - val_loss: 2.2504 - val_accuracy_function: 0.3307
Epoch 7/10
7788/7788 [==============================] - 2772s 356ms/step - loss: 1.6158 - accuracy_function: 0.3350 - val_loss: 2.2576 - val_accuracy_function: 0.3384
Epoch 8/10
7788/7788 [==============================] - 2773s 356ms/step - loss: 1.5331 - accuracy_function: 0.3424 - val_loss: 2.2779 - val_accuracy_function: 0.3457
Epoch 9/10
7788/7788 [==============================] - 2771s 356ms/step - loss: 1.4556 - accuracy_function: 0.3496 - val_loss: 2.3189 - val_accuracy_function: 0.3528
Epoch 10/10
7788/7788 [==============================] - 2771s 356ms/step - loss: 1.3830 - accuracy_function: 0.3565 - val_loss: 2.3518 - val_accuracy_function: 0.3596
Epoch 1/10
88/88 [==============================] - 40s 368ms/step - loss: 2.4615 - accuracy_function: 0.3596 - val_loss: 2.4174 - val_accuracy_function: 0.3596
Epoch 2/10
88/88 [==============================] - 31s 352ms/step - loss: 2.0226 - accuracy_function: 0.3596 - val_loss: 2.4313 - val_accuracy_function: 0.3596
Epoch 3/10
88/88 [==============================] - 31s 352ms/step - loss: 1.6938 - accuracy_function: 0.3596 - val_loss: 2.5127 - val_accuracy_function: 0.3596
Epoch 4/10
88/88 [==============================] - 31s 352ms/step - loss: 1.3925 - accuracy_function: 0.3597 - val_loss: 2.6313 - val_accuracy_function: 0.3597
Epoch 5/10
88/88 [==============================] - 31s 352ms/step - loss: 1.1290 - accuracy_function: 0.3598 - val_loss: 2.7556 - val_accuracy_function: 0.3599
Epoch 6/10
88/88 [==============================] - 31s 352ms/step - loss: 0.9081 - accuracy_function: 0.3600 - val_loss: 2.8535 - val_accuracy_function: 0.3601
Epoch 7/10
88/88 [==============================] - 31s 352ms/step - loss: 0.7357 - accuracy_function: 0.3603 - val_loss: 2.9307 - val_accuracy_function: 0.3604
Epoch 8/10
88/88 [==============================] - 31s 352ms/step - loss: 0.6019 - accuracy_function: 0.3605 - val_loss: 2.9984 - val_accuracy_function: 0.3607
Epoch 9/10
88/88 [==============================] - 31s 352ms/step - loss: 0.5033 - accuracy_function: 0.3608 - val_loss: 3.0530 - val_accuracy_function: 0.3610
Epoch 10/10
88/88 [==============================] - 31s 352ms/step - loss: 0.4324 - accuracy_function: 0.3612 - val_loss: 3.0938 - val_accuracy_function: 0.3613